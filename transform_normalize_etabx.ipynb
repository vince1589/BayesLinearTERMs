{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "#Set some List\n",
    "myAA = [\"R\",\"H\",\"K\",\"D\",\"E\",\"S\",\"T\",\"N\",\"Q\",\"C\",\"G\",\"P\",\"A\",\"V\",\"I\",\"L\",\"M\",\"F\",\"Y\",\"W\"]\n",
    "FullAmino = [\"ARG\",\"HIS\",\"LYS\",\"ASP\",\"GLU\",\"SER\",\"THR\",\"ASN\",\"GLN\",\"CYS\",\"GLY\",\"PRO\",\"ALA\",\"VAL\",\"ILE\",\"LEU\",\"MET\",\"PHE\",\"TYR\",\"TRP\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function that read PDB file and store every atoms in an array\n",
    "#Each array entries is a dict\n",
    "#Mask allow you to keep only certain type of atoms\n",
    "\n",
    "def read_pdb_seq(myF,keep_hydrogen = 1,keep_het = 1,mask=\"\"):\n",
    "    lines = [line.rstrip('\\n') for line in open(myF)]\n",
    "    Nresnumc = \"NA\"\n",
    "    myPDB = []\n",
    "    myC = 0\n",
    "    for l in lines:\n",
    "     # print(l)\n",
    "        # My hash\n",
    "        raw = {}\n",
    "        if (re.search(' H\\s*$',l) != None and keep_hydrogen == 0):\n",
    "            continue\n",
    "        if (re.search('^HET',l) != None and keep_het == 0):\n",
    "            continue\n",
    "        if mask != \"\":\n",
    "            pattern = re.compile(mask)\n",
    "            if not pattern.search(l):\n",
    "                continue\n",
    "        m = re.search('^ATOM........(....).(...) (.)\\s*(\\d+)\\s*(-*\\d+\\.\\d{3})\\s*(-*\\d+.\\d{3})\\s*(-*\\d+.\\d{3})', l)\n",
    "        if (m == None):\n",
    "            print('Can t find patern in '+l)\n",
    "            continue\n",
    "        # Get resnumc\n",
    "        resnumc = str(m.group(2)) + \" \" + str(m.group(4)) + \" \" + str(m.group(3))\n",
    "     # print(m.group(4,5,6))\n",
    "        myCord = m.group(5,6,7)\n",
    "        nCord = [float(i) for i in myCord]\n",
    "        raw['coord'] = nCord\n",
    "        raw['res'] = m.group(2)\n",
    "        raw['num'] = m.group(4)\n",
    "        raw['cha'] = m.group(3)\n",
    "        raw['atom'] = m.group(1)\n",
    "        raw['resnumc'] = resnumc\n",
    "        raw['ID'] = myC\n",
    "        myC += 1\n",
    "        myPDB.append(raw)\n",
    "     # break\n",
    "    return(myPDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function that read the etabx file\n",
    "#THis file is a log file from dTERMen and we can get stat and invidual score\n",
    "\n",
    "def get_etabx_stat(etabx):\n",
    "    #Open File\n",
    "    lines = [line.rstrip('\\n') for line in open(etabx)]\n",
    "    \n",
    "    #Stat for count\n",
    "    TermSTAT = dict()\n",
    "    \n",
    "    #Some Scoring\n",
    "    TermScor = dict()\n",
    "    \n",
    "    for l in lines:\n",
    "        #Skip small line\n",
    "        if len(l) < 40:\n",
    "            continue\n",
    "            \n",
    "        #Find what peppos it is\n",
    "        m = re.search(\"^[A-Za-z0-9_]+\\((.),(\\d+), (\\S+), (.)\",l)\n",
    "        if m == None:\n",
    "            print(l)\n",
    "            continue\n",
    "        ch = m.group(1)\n",
    "        num = m.group(2)\n",
    "        res = m.group(4)\n",
    "        \n",
    "        #RES,NUM,C\n",
    "        kr = \",\".join([res,num,ch])\n",
    "        #NUM,C\n",
    "        numc = \",\".join([num,ch])\n",
    "        \n",
    "        #Init some dict\n",
    "        if kr not in TermScor:\n",
    "            TermScor[kr] = dict()\n",
    "        #Init some dict\n",
    "        if numc not in TermSTAT:\n",
    "            TermSTAT[numc] = dict()\n",
    "        \n",
    "        #This is some selfcorrectin score (I think)\n",
    "        #Just get the score and next\n",
    "        if \"SelfCorr\" in l:\n",
    "            #Will next for now\n",
    "            continue\n",
    "            sp = re.split(\"\\s+\",l)\n",
    "            TermScor[kr][kr] = TermScor[kr].get(kr,0.0)+float(sp[-1])\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        #Load self score\n",
    "        m = re.search(\"SelfScore\\((.),(\\d+),.*, .\\).*\\/(\\d+)\",l)\n",
    "        if m != None:\n",
    "            ener = re.split(\"\\s+\",l)[-1][:-1]\n",
    "            TermScor[kr][kr] = TermScor[kr].get(kr,0.0)+float(ener)\n",
    "            TermSTAT[numc][numc] = int(m.group(3))\n",
    "            continue\n",
    "            \n",
    "        #Pair score\n",
    "        if re.search(\"PairScore\\(.*, .\\) \\(IMM\",l):\n",
    "            m = re.search(\"PairScore\\(B,(\\d+),.*\\/(\\d+)\",l)\n",
    "            sp = re.split(\"\\(IMM\",l)\n",
    "            for spl in sp[1:]:\n",
    "                m = re.search(\" (\\S,\\d+).*(.)\\).*\\/(\\d+).*\\s+(\\S+)\\]\",spl)\n",
    "                ener = m.group(4)\n",
    "                cou = m.group(3)\n",
    "                ma = re.split(\"\\s*,\\s*\",spl.split(\")\")[0][1:])\n",
    "                recpos = \",\".join([ma[3],ma[2],ma[0]])\n",
    "                numct = \",\".join(m.group(1).split(\",\")[::-1])\n",
    "                \n",
    "                \n",
    "                TermSTAT[numc][numct] = int(cou)\n",
    "                #Store Energy\n",
    "                TermScor[kr][recpos] = float(ener)\n",
    "                if recpos not in TermScor:\n",
    "                    TermScor[recpos] = dict()\n",
    "                TermScor[recpos][kr] = float(ener)\n",
    "            continue\n",
    "        m = re.search(\"PairScore\\((.),(\\d+), \\d+, ., B,(\\d+), \\d+, (.)\\).*/(\\d+).*]\\s+(\\S+)\",l)\n",
    "        if m == None:\n",
    "            continue\n",
    "        tkr = \",\".join([m.group(4),m.group(3),m.group(1)])\n",
    "        numct = \",\".join([m.group(3),m.group(1)])\n",
    "        ener = float(m.group(6))\n",
    "        cou = int(m.group(5))\n",
    "        #Update term score\n",
    "        TermScor[kr][tkr] = float(ener)\n",
    "        if tkr not in TermScor:\n",
    "            TermScor[tkr] = dict()\n",
    "        TermScor[tkr][kr] = float(ener)\n",
    "        #Update term stat\n",
    "        TermSTAT[numc][numct] = float(cou)\n",
    "        #if numct not in TermScor:\n",
    "        #    TermSTAT[numct] = dict()\n",
    "    \n",
    "    #Fill the matrices\n",
    "    for x in sorted(TermSTAT):\n",
    "        for xt in sorted(TermSTAT[x].keys()):\n",
    "            if xt not in TermSTAT:\n",
    "                TermSTAT[xt] = dict()\n",
    "            TermSTAT[xt][x] = TermSTAT[x][xt]\n",
    "    for x in sorted(TermScor):\n",
    "        for xt in sorted(TermScor[x].keys()):\n",
    "            if xt not in TermScor:\n",
    "                TermScor[xt] = dict()\n",
    "            TermScor[xt][x] = TermScor[x][xt]\n",
    "    return(TermSTAT,TermScor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Alignemnt\n",
    "# (I have already aligned receptor sequence)\n",
    "#Alignment is usufell to know sequence composition of Binding Site in other receptor\n",
    "f = \"./data/BenchRecep.aln\"\n",
    "lines = [line.rstrip('\\n') for line in open(f)]\n",
    "AllAli = dict()\n",
    "\n",
    "\n",
    "for l in lines[3:-1]:\n",
    "    sp = re.split(\"\\s+\",l)\n",
    "    if len(sp[0]) < 2:continue\n",
    "    if len(l) < 10:\n",
    "        continue\n",
    "    if len(sp) != 2:continue\n",
    "    if sp[0] not in AllAli:\n",
    "        AllAli[sp[0]] = []\n",
    "    AllAli[sp[0]] += list(sp[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#This is all the etbax\n",
    "PathToEtab = \"/media/vince/Postdoc/dTERMn/scoring/\"\n",
    "PathToEtab = \"./\"\n",
    "\n",
    "alletab = sorted(glob.glob(PathToEtab+\"./energy_table/*_HUMAN_*_holo_35.etabx\"))\n",
    "print(len(alletab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "././energy_table/B2CL1_HUMAN_1BXL_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_1G5J_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_2M04_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_2P1L_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_2P1L_C_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_2P1L_E_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_2P1L_G_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_2PON_B_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_2YQ7_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_3FDL_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_3IO8_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_3IO8_C_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_3PL7_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_3R85_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_3R85_B_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_3R85_C_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_3R85_D_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_4CIN_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_4CIN_B_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_4HNJ_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_4QVE_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_4QVF_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_5B1Z_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_5B1Z_B_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_5FMJ_A_holo_35.etabx\n",
      "././energy_table/B2CL1_HUMAN_5FMK_A_holo_35.etabx\n",
      "././energy_table/B2LA1_HUMAN_2VM6_A_holo_35.etabx\n",
      "././energy_table/B2LA1_HUMAN_3I1H_A_holo_35.etabx\n",
      "././energy_table/B2LA1_HUMAN_3MQP_A_holo_35.etabx\n",
      "././energy_table/B2LA1_HUMAN_4ZEQ_A_holo_35.etabx\n",
      "././energy_table/B2LA1_HUMAN_5UUK_A_holo_35.etabx\n",
      "././energy_table/B2LA1_HUMAN_5UUL_A_holo_35.etabx\n",
      "././energy_table/B2LA1_HUMAN_5UUP_A_holo_35.etabx\n",
      "././energy_table/B2LA1_HUMAN_GVF1_A_holo_35.etabx\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './query_pdb/B2LA1_HUMAN_GVF1_A_holo.pdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f636b579b28f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpdbName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_pdb_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./query_pdb/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpdbName\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pdb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_hydrogen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_het\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ATOM.* CA .*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#Loab scoring matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c970e2bcac29>\u001b[0m in \u001b[0;36mread_pdb_seq\u001b[0;34m(myF, keep_hydrogen, keep_het, mask)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_pdb_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_hydrogen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_het\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mNresnumc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"NA\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmyPDB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './query_pdb/B2LA1_HUMAN_GVF1_A_holo.pdb'"
     ]
    }
   ],
   "source": [
    "\n",
    "#Here I'm loading all the scoring matrix\n",
    "#I'm also normalizing the peptide-receptor interaction, so that they are constant across template (and receptor)\n",
    "\n",
    "AllNormScore = dict()\n",
    "BindingMode = dict()\n",
    "CountContact = dict()\n",
    "for etab in alletab:\n",
    "    #Use only croped\n",
    "    if \"lp\" in etab:continue\n",
    "    if \"5C3F\" in etab:continue\n",
    "    print(etab)\n",
    "    pdbName = \"_\".join(etab.split(\"/\")[-1].split(\"_\")[:-1])\n",
    "    pdb = read_pdb_seq(\"./query_pdb/\"+pdbName+\".pdb\",keep_hydrogen = 0,keep_het = 0,mask=\"ATOM.* CA .*\")\n",
    "    \n",
    "    #Loab scoring matrix\n",
    "    (TermSTAT,TermScor) = get_etabx_stat(etab)\n",
    "    #Check pep len\n",
    "    PepK = []\n",
    "    for k in TermSTAT.keys():\n",
    "        if \",B\" not in k:continue\n",
    "        PepK.append(k)\n",
    "    if len(PepK) != 20:continue\n",
    "    \n",
    "    #Transform recep k to universal number\n",
    "    if pdbName not in AllAli:\n",
    "        continue\n",
    "    nAli = AllAli[pdbName]\n",
    "    c = 0\n",
    "    Transformed = dict()\n",
    "    for i in range(len(nAli)):\n",
    "        if nAli[i] == \"-\":continue\n",
    "\n",
    "        nk = \",\".join([myAA[FullAmino.index(pdb[c][\"res\"])],str(c),pdb[c][\"cha\"]])\n",
    "        unk = \",\".join([myAA[FullAmino.index(pdb[c][\"res\"])],str(i),pdb[c][\"cha\"]])\n",
    "        Transformed[nk] = unk\n",
    "        c += 1\n",
    "\n",
    "    AllNormScore[pdbName] = dict()\n",
    "    BindingMode[pdbName] = []\n",
    "    for k in sorted(TermScor.keys()):\n",
    "        nk = k\n",
    "        if \",A\" in k:\n",
    "            nk = Transformed[k]\n",
    "        if nk not in AllNormScore[pdbName]:\n",
    "            AllNormScore[pdbName][nk] = dict()\n",
    "        if nk not in CountContact:\n",
    "            CountContact[nk] = dict()\n",
    "        \n",
    "       \n",
    "        for k1 in sorted(TermScor[k].keys()):\n",
    "            nk1 = k1\n",
    "            if \",A\" in k1:\n",
    "                nk1 = Transformed[k1]\n",
    "            AllNormScore[pdbName][nk][nk1] = TermScor[k][k1]\n",
    "            \n",
    "            if nk1 not in CountContact[nk]:\n",
    "                CountContact[nk][nk1] = 0\n",
    "            CountContact[nk][nk1] += 1\n",
    "            #if (\",A\" in k1) and (\",B\" in k):\n",
    "            occk = nk[2:] + \" \" +nk1[2:]\n",
    "            if occk not in BindingMode[pdbName]:\n",
    "                BindingMode[pdbName].append(occk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Look at overlap between binding mode\n",
    "#A binding mode is made of receptor-protein contact\n",
    "\n",
    "Overlap = dict()\n",
    "for pdb1 in BindingMode.keys():\n",
    "    bs1 = BindingMode[pdb1]\n",
    "    Overlap[pdb1] = dict()\n",
    "    for pdb2 in BindingMode.keys():\n",
    "        bs2 = BindingMode[pdb2]\n",
    "        over = len(np.intersect1d(bs1,bs2))/np.mean([len(bs1),len(bs2)])\n",
    "        Overlap[pdb1][pdb2] = over\n",
    "    print(pdb1,pdb2,len(np.intersect1d(bs1,bs2)),len(bs1),len(bs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OverlapDF = pd.DataFrame(Overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.clustermap(pd.DataFrame(Overlap),figsize=(20,20),cmap=\"Blues\",vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove binding mode that are \"too unique\"\n",
    "#I think they might be bad crystal structrure\n",
    "\n",
    "ToKeep = OverlapDF.columns\n",
    "ToRemove = []\n",
    "for i in range(10):\n",
    "    tr = OverlapDF[ToKeep].transpose()[ToKeep].mean().sort_values().index[0]\n",
    "    val = OverlapDF[ToKeep].transpose()[ToKeep].mean().sort_values().values[0]\n",
    "    ToRemove.append(tr)\n",
    "    print(tr,val)\n",
    "    Nkeep = []\n",
    "    for t in ToKeep:\n",
    "        if t in ToRemove:continue\n",
    "        Nkeep.append(t)\n",
    "    ToKeep = Nkeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(OverlapDF[ToKeep].transpose()[ToKeep],cmap=\"Blues\",vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ToKeep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f4b79a9e9154>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPairOccurence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpdb1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mToKeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBindingMode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpdb1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbs1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ToKeep' is not defined"
     ]
    }
   ],
   "source": [
    "PairOccurence = dict()\n",
    "for pdb1 in ToKeep:\n",
    "    bs1 = BindingMode[pdb1]\n",
    "    rec = pdb1.split(\"_\")[0]\n",
    "    for b in bs1:\n",
    "        if b not in PairOccurence:PairOccurence[b] = dict()\n",
    "        if rec not in PairOccurence[b]:PairOccurence[b][rec] = 0\n",
    "        PairOccurence[b][rec] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function return the number of times a contact is found in each recep\n",
    "def ConserContact(p1,maxp,tr=0.5):\n",
    "    MinO = []\n",
    "    for k in maxp:\n",
    "        #print(k,maxp[k],p1[k])\n",
    "        if k not in p1:\n",
    "            MinO.append(0)\n",
    "            continue\n",
    "        MinO.append(p1[k]/float(maxp[k]))\n",
    "\n",
    "    return(MinO)\n",
    "#ConserContact(PairOccurence[k],MaxPair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to keep contact that are frequent\n",
    "MaxPair = PairOccurence[\"108,B 108,B\"]\n",
    "print(ConserContact(PairOccurence[\"108,B 108,B\"],MaxPair))\n",
    "KeptPair = []\n",
    "AllMinOverlap = []\n",
    "\n",
    "for k in PairOccurence:\n",
    "    #print(k,PairOccurence[k],ConserContact(PairOccurence[k],MaxPair))\n",
    "    MinO = ConserContact(PairOccurence[k],MaxPair)\n",
    "    AllMinOverlap.append(np.min(MinO))\n",
    "    if np.min(MinO) < 0.5:\n",
    "        #print(k,PairOccurence[k],ConserContact(PairOccurence[k],MaxPair))\n",
    "        continue\n",
    "    KeptPair.append(k)\n",
    "#    break\n",
    "print(len(KeptPair),len(PairOccurence))\n",
    "plt.hist(AllMinOverlap,20)\n",
    "plt.show()\n",
    "plt.hist(AllMinOverlap,20,cumulative=1,density=True)\n",
    "plt.title(\"cumulative Distributin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AllScore = dict()\n",
    "ReceptorContact = dict()\n",
    "ReceptorContact[\"All\"] = []\n",
    "AllFeat = []\n",
    "for k1 in sorted(CountContact):\n",
    "    sk1 = k1[2:]\n",
    "    for k2 in sorted(CountContact[k1]):\n",
    "        sk2 = k2[2:]\n",
    "        occk = sk1 + \" \" + sk2\n",
    "        if occk not in KeptPair:\n",
    "            continue\n",
    "        cont_ks = \" \".join(sorted([k1,k2]))\n",
    "        if cont_ks in AllFeat:\n",
    "            continue\n",
    "        AllFeat.append(cont_ks)\n",
    "        for pdbname in AllNormScore:\n",
    "            if k1 not in AllNormScore[pdbname]:continue\n",
    "            if k2 not in AllNormScore[pdbname][k1]:continue\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if cont_ks not in AllScore:AllScore[cont_ks] = []\n",
    "            \n",
    "            AllScore[cont_ks].append(AllNormScore[pdbname][k1][k2])\n",
    "            recep = pdbname.split(\"_\")[0]\n",
    "            if recep not in ReceptorContact:\n",
    "                ReceptorContact[recep] = []\n",
    "            if \",A\" in k2:\n",
    "                if k2 not in ReceptorContact[recep]:\n",
    "                    ReceptorContact[recep].append(k2)\n",
    "                if k2 not in ReceptorContact[\"All\"]:\n",
    "                    ReceptorContact[\"All\"].append(k2)\n",
    "                    #print(recep,k2)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I have this many feature=%d\" % len(AllFeat))\n",
    "print(\"A feature is a contact and a amino acid (Ex:pos 182,A ALA and pos 202B, ARG)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write everything\n",
    "pickle.dump(AllScore,open(\"./data/AllNormScore_small.pk\",\"wb\"))\n",
    "pickle.dump(ReceptorContact,open(\"./data/ReceptorContact_small.pk\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the overlap between each binding site\n",
    "BindingSiteOver = dict()\n",
    "Unique = ReceptorContact[\"All\"]\n",
    "for r1 in ReceptorContact:\n",
    "    Unique = np.intersect1d(Unique,ReceptorContact[r1])\n",
    "ReceptorContact[\"Unique\"] = Unique\n",
    "\n",
    "#Combine\n",
    "keys = list(ReceptorContact.keys())\n",
    "for r1 in keys:\n",
    "    for r2 in keys:\n",
    "        if r1 == r2:continue\n",
    "        k = \" \".join(sorted([r1,r2]))\n",
    "        if \"All\" in k:continue\n",
    "        if \"Unique\" in k:continue\n",
    "        if \" \" in r1:continue\n",
    "        if \" \" in r2:continue\n",
    "        if k in ReceptorContact:continue\n",
    "        ReceptorContact[k] = np.unique(ReceptorContact[r1]+ReceptorContact[r2])\n",
    "OneRecep = [\"B2LA1\",\"MCL1\",\"B2CL1\"]\n",
    "for r1 in OneRecep:\n",
    "    BindingSiteOver[r1] = dict()\n",
    "    RecepO = []\n",
    "    for r2 in ReceptorContact:\n",
    "        bs1 = ReceptorContact[r1]\n",
    "        bs2 = ReceptorContact[r2]\n",
    "        #print(r1,r2,len(np.intersect1d(bs1,bs2)),len(bs1),len(bs2))\n",
    "        BindingSiteOver[r1][r2] = len(np.intersect1d(bs1,bs2))\n",
    "        if \"All\" in r1+r2:continue\n",
    "        if \"Unique\" in  r1+r2:continue\n",
    "        if r1 == r2:continue\n",
    "        if r1 in r2:continue\n",
    "        if r2 in r1:continue\n",
    "        RecepO.append(BindingSiteOver[r1][r2])\n",
    "    print(\"%8s max BS overlap = %d\" % (r1,max(RecepO)))\n",
    "        #print(r1,r2,BindingSiteOver[r1][r2])\n",
    "sns.clustermap(pd.DataFrame(BindingSiteOver)[[\"B2LA1\",\"MCL1\",\"B2CL1\"]],cmap=\"Blues\",vmin=0,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Unique' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f6cb2763e08e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mUnique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Unique' is not defined"
     ]
    }
   ],
   "source": [
    "Unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
